{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "mighty-mobile",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-09-08T22:22:48.346747Z",
     "start_time": "2022-09-08T22:22:45.625754Z"
    }
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "# import scipy.stats as ss\n",
    "# from scipy.spatial import distance_matrix\n",
    "import random\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "from sklearn.cluster import SpectralClustering\n",
    "from sklearn.metrics.cluster import adjusted_rand_score\n",
    "from tqdm.notebook import tqdm\n",
    "from collections import defaultdict\n",
    "from multiprocessing import Pool\n",
    "import anndata\n",
    "import scanpy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "spoken-stylus",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-09-08T22:22:48.351805Z",
     "start_time": "2022-09-08T22:22:48.349294Z"
    }
   },
   "outputs": [],
   "source": [
    "INPUT_PATH=\"/mnt/geofflab/SNP_barcoding/Lvar_annotations_v3_Jan2021/transcripts.csv\"\n",
    "COUNTS_PATH=\"/mnt/geofflab/SNP_barcoding/LV_counts_10hpf.csv\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "dietary-minutes",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-09-08T22:22:48.361337Z",
     "start_time": "2022-09-08T22:22:48.354041Z"
    }
   },
   "outputs": [],
   "source": [
    "heterozygosity = 0.001 # This is the rate of SNPs per base\n",
    "alphabet = {\"A\":0, \"C\":1, \"G\":2, \"T\":3}\n",
    "\n",
    "# genotypes where chromosome order matters (used internally during generation)\n",
    "genotypes_internal = {\n",
    "    \"AA\":0, \"AC\":1, \"AG\":2, \"AT\":3, \n",
    "    \"CA\":4, \"CC\":5, \"CG\":6, \"CT\":7,\n",
    "    \"GA\":8, \"GC\":9, \"GG\":10, \"GT\":11, \n",
    "    \"TA\":12, \"TC\":13, \"TG\":14, \"TT\":15,\n",
    "}\n",
    "\n",
    "# genotypes where chromosome order doesn't matter (what we see)\n",
    "genotypes_external = {\n",
    "\"AA\":0, \"AC\":1, \"AG\":2, \"AT\":3, \n",
    "\"CA\":1, \"CC\":4, \"CG\":5, \"CT\":6,\n",
    "\"GA\":2, \"GC\":4, \"GG\":7, \"GT\":8, \n",
    "\"TA\":3, \"TC\":6, \"TG\":8, \"TT\":9,\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "revolutionary-sally",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-09-08T22:41:00.615450Z",
     "start_time": "2022-09-08T22:41:00.578610Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/mnt/geofflab/jupyterhub/anaconda3/lib/python3.7/site-packages/ipykernel/ipkernel.py:287: DeprecationWarning: `should_run_async` will not call `transform_cell` automatically in the future. Please pass the result to `transformed_cell` argument and any exception that happen during thetransform in `preprocessing_exc_tuple` in IPython 7.17 and above.\n",
      "  and should_run_async(code)\n"
     ]
    }
   ],
   "source": [
    "def sample_dropout_profile(args):\n",
    "    \"\"\"\n",
    "    Sample a dropout profile from single-cell transcript read count df, and \n",
    "    introduce dropout over the snp_profile according to the dropout profile.\n",
    "    \"\"\"\n",
    "    global adata_counts\n",
    "    snps = args[0].copy()\n",
    "    loci_map = args[1]\n",
    "    \n",
    "    np.random.seed()\n",
    "    \n",
    "    # Sample a cell's counts\n",
    "    sampled_dprofile = np.random.choice(adata_counts.obs.index)\n",
    "\n",
    "    for gene in adata_counts.var.index:\n",
    "        count = int(adata_counts[sampled_dprofile, gene].X)\n",
    "\n",
    "        # If we have no counts, then we have can't detect the genotype\n",
    "        if count <= 1:\n",
    "            for locus in loci_map[gene]:\n",
    "                snps[locus] = -1 # -1 genotype -> undetected\n",
    "        else:\n",
    "            # Otherwise compute the probability of only seeing one of the chromosomes, or both\n",
    "            prob_one = 0.5**count\n",
    "            prob_both = 1 - 2*prob_one\n",
    "\n",
    "            # Now choose whether we only see the first chromosome, second chromosome, or both\n",
    "            seen = np.random.choice([0, 1, 2], p=[prob_one, prob_one, prob_both])\n",
    "\n",
    "            if seen == 0:\n",
    "                # Convert internal to external genotypes on the first chromosome\n",
    "                first_mapping = {0:0, 1:0, 2:0, 3:0,\n",
    "                                 4:4, 5:4, 6:4, 7:4,\n",
    "                                 8:7, 9:7, 10:7, 11:7,\n",
    "                                 12:9, 13:9, 14:9, 15:9}\n",
    "\n",
    "                # Convert the SNP read to it's value on one of the chromosomes\n",
    "                for snp_loc in loci_map[gene]:\n",
    "                    snps[snp_loc] = first_mapping[snps[snp_loc]]\n",
    "\n",
    "            elif seen == 1:\n",
    "                # Convert internal to external genotypes on the first chromosome\n",
    "                second_mapping = {0:0, 1:4, 2:7, 3:9,\n",
    "                                 4:0, 5:4, 6:7, 7:9,\n",
    "                                 8:0, 9:4, 10:7, 11:9,\n",
    "                                 12:0, 13:4, 14:7, 15:9}\n",
    "\n",
    "                # Convert the SNP read to it's value on one of the chromosomes\n",
    "                for snp_loc in loci_map[gene]:\n",
    "                    snps[snp_loc] = second_mapping[snps[snp_loc]]\n",
    "\n",
    "            else:\n",
    "\n",
    "                # Convert internal to external genotypes on both chromosomes\n",
    "                both_mapping = {0:0, 1:1, 2:2, 3:3,\n",
    "                                 4:1, 5:4, 6:5, 7:6,\n",
    "                                 8:2, 9:4, 10:7, 11:8,\n",
    "                                 12:3, 13:6, 14:8, 15:9}\n",
    "\n",
    "                # Convert the SNP read to it's value on one of the chromosomes\n",
    "                for snp_loc in loci_map[gene]:\n",
    "                    snps[snp_loc] = both_mapping[snps[snp_loc]]\n",
    "\n",
    "    return snps\n",
    "\n",
    "class EmbryoSequenceSimulator:\n",
    "    def __init__(self, input_df, n_embryos):\n",
    "        \n",
    "        # pd data frame\n",
    "        self.input_df = input_df # cols: gene,chromosome,start,end,direction,sequence\n",
    "        self.n_embryos = n_embryos\n",
    "        \n",
    "        # Number of cells that can be harvested from embryo\n",
    "        self.avg_harvested_cells = 20\n",
    "        self.sd_harvested_cells = 3\n",
    "        self.alphabet = {\"A\":0, \"C\":1, \"G\":2, \"T\":3}\n",
    "        \n",
    "        # Global parental chromatid maps\n",
    "        self.m0_chromatid = None\n",
    "        self.m1_chromatid = None\n",
    "        self.p0_chromatid = None\n",
    "        self.p1_chromatid = None\n",
    "        \n",
    "    def global_seeding(self, heterozygosity):\n",
    "        \"\"\"\n",
    "        Uniform seeding of SNP locations for each gene with frequency according to heterozygosity.\n",
    "        Parental chromatid seeding (2 chromatids from mother, 2 chromatids from father)\n",
    "        \"\"\"\n",
    "        \n",
    "        # All the SNPs present in the parents\n",
    "        snp_map_overall = None\n",
    "        \n",
    "        # Setting parental chromatid maps\n",
    "        for parent in [\"m0\",\"m1\",\"p0\",\"p1\"]:\n",
    "            \n",
    "            # Create a profile of SNPs for each parent chromosome\n",
    "            snp_map = defaultdict(dict)\n",
    "            sequence_map = defaultdict(dict)\n",
    "            \n",
    "            for idx,transcript_entry in self.input_df.iterrows():\n",
    "                gene,chrom,start,end,direction,sequence = transcript_entry\n",
    "                N = len(sequence)\n",
    "                num_snps = np.random.binomial(N, p=heterozygosity)\n",
    "                snp_positions = list(np.sort(random.sample(range(N),num_snps)))\n",
    "                snp_map[chrom][gene] = snp_positions\n",
    "                sequence_map[chrom][gene] = sequence\n",
    "                \n",
    "            # Add the snp map we just made to the global collection of SNPs\n",
    "            if snp_map_overall is None:\n",
    "                snp_map_overall = snp_map\n",
    "            else:\n",
    "                for idx,transcript_entry in self.input_df.iterrows():\n",
    "                    gene,chrom,start,end,direction,sequence = transcript_entry\n",
    "                    snp_map_overall[chrom][gene].extend(snp_map[chrom][gene])\n",
    "            \n",
    "            chromatid = defaultdict(dict)\n",
    "            # If we have a SNP, this is the probability of going reference to \n",
    "            transition_probs = np.array([[0, 1/3, 1/3, 1/3],\n",
    "                                         [1/3, 0, 1/3, 1/3],\n",
    "                                         [1/3, 1/3, 0, 1/3],\n",
    "                                         [1/3, 1/3, 1/3, 0]])\n",
    "            \n",
    "            for chrom,genes in snp_map.items():            \n",
    "                for gene,snp_positions in genes.items():\n",
    "                    sequence_list = [char for char in sequence_map[chrom][gene]]\n",
    "                    snp_profile = {locus:np.random.choice(list(self.alphabet.keys()), \n",
    "                                                          p=transition_probs[alphabet[sequence_list[locus]]]) for locus in snp_positions}\n",
    "                    \n",
    "                    for locus,char in snp_profile.items():\n",
    "                        sequence_list[locus] = char\n",
    "                    \n",
    "                    chromatid[chrom][gene] = \"\".join(sequence_list)\n",
    "                \n",
    "            # Assign seeded parental chromatid to its class field (global over all embryos)\n",
    "            if parent == \"m0\":\n",
    "                self.m0_chromatid = chromatid\n",
    "            elif parent == \"m1\":\n",
    "                self.m1_chromatid = chromatid\n",
    "            elif parent == \"p0\":\n",
    "                self.p0_chromatid = chromatid\n",
    "            elif parent == \"p1\":\n",
    "                self.p1_chromatid = chromatid\n",
    "                \n",
    "        return snp_map_overall\n",
    "    \n",
    "    def embryo_population_simulation(self):\n",
    "        \"\"\"\n",
    "        Simulating SNP profile for each embryo across all transcript entries in input_df.\n",
    "        For this simulator, not explicitly generating scRNA-seq reads for each embryo (reduces space)\n",
    "        \"\"\"\n",
    "\n",
    "        # map: idx of transcript entry -> list of snp positions\n",
    "        snp_map = self.global_seeding(heterozygosity)\n",
    "        true_clusters = []\n",
    "        cluster_label = 0\n",
    "        \n",
    "        population_profile = [] # The variant calls for the cells\n",
    "        \n",
    "        p = Pool(NUM_PROC)\n",
    "        \n",
    "        for embryo in range(self.n_embryos):\n",
    "            \n",
    "            # Each entry a list of genotypes for an embryo across all transcripts\n",
    "            snp_profile,gene_locus_map = self.determine_embryo_genotype(snp_map)\n",
    "\n",
    "            # Harvest some number of cells, which will theoretically have identical SNP profiles\n",
    "            n_harvested_cells = round(np.random.normal(self.avg_harvested_cells,self.sd_harvested_cells))\n",
    "            \n",
    "            # Parallelize making the cells\n",
    "            new_cells = list(tqdm(p.imap(sample_dropout_profile, \n",
    "                                    zip([snp_profile]*n_harvested_cells, \n",
    "                                        [gene_locus_map]*n_harvested_cells)), \n",
    "                                  total=n_harvested_cells, desc=f'Embryo {embryo}'))\n",
    "                \n",
    "            population_profile.extend(new_cells)\n",
    "\n",
    "            \n",
    "            # Mark the cluster of the cells we just created\n",
    "            for _ in range(n_harvested_cells):\n",
    "                true_clusters.append(cluster_label)\n",
    "            \n",
    "            cluster_label += 1\n",
    "            \n",
    "        p.close()\n",
    "                \n",
    "        return np.array(population_profile),true_clusters\n",
    "        \n",
    "    \n",
    "    def determine_embryo_genotype(self, snp_map):\n",
    "        \"\"\"\n",
    "        Simulate array containing genotypes over all transcripts \n",
    "        (concatenated into single list)\n",
    "        \"\"\"\n",
    "                \n",
    "        # state (genotype) across all transcripts\n",
    "        snp_genotypes,idx = [],0\n",
    "        gene_locus_map = defaultdict(list)\n",
    "                \n",
    "        # map: idx of transcript entry -> sequence after homologous recombination\n",
    "        m_chromatid,p_chromatid = self.simulate_embryo_sequence()\n",
    "        for chrom,genes in snp_map.items():\n",
    "            for gene,snp_positions in genes.items():                \n",
    "                m_sequence = m_chromatid[chrom][gene]\n",
    "                p_sequence = p_chromatid[chrom][gene]\n",
    "                for locus in snp_positions:\n",
    "                    snp_genotype = \"\".join([m_sequence[locus],p_sequence[locus]])\n",
    "                    snp_genotypes.append(genotypes_internal[snp_genotype])\n",
    "                    gene_locus_map[gene].append(idx)\n",
    "                    idx += 1\n",
    "                \n",
    "        return snp_genotypes,gene_locus_map\n",
    "                \n",
    "    def simulate_embryo_sequence(self):\n",
    "        \"\"\"\n",
    "        Given seeded parental chromatids and a map of SNP locations for each transcript,\n",
    "        simulate embryo sequences\n",
    "        \"\"\"\n",
    "        \n",
    "        updated_m0,updated_m1 = defaultdict(dict),defaultdict(dict)\n",
    "        updated_p0,updated_p1 = defaultdict(dict),defaultdict(dict)\n",
    "        \n",
    "        for parent in [\"mother\",\"father\"]:\n",
    "            \n",
    "            # Consider homologous recombination with respect to each chromosome\n",
    "            for chr_num in np.sort(np.unique(df[\"chromosome\"])):\n",
    "                \n",
    "                # Subset df for specific chr, sorted by start position \n",
    "                chr_df = self.input_df[self.input_df[\"chromosome\"] == chr_num].sort_values(by=[\"start\"])\n",
    "                \n",
    "                # Chiasma point chosen over range of transcripts reads\n",
    "                transcript_range = range(chr_df[\"start\"].iloc[0], chr_df[\"start\"].iloc[-1]+len(chr_df[\"sequence\"].iloc[-1])) \n",
    "                chiasma = random.choice(transcript_range)\n",
    "                chiasma_flag = 1 # 1 means chiasma has not been reached; 0 means passed chiasma\n",
    "                for idx,transcript_entry in chr_df.iterrows():\n",
    "                    if parent == \"mother\":\n",
    "                        chiasma_flag = self.homologous_recombination(\n",
    "                            transcript_entry = transcript_entry,\n",
    "                            updated_c0 = updated_m0,\n",
    "                            updated_c1 = updated_m1,\n",
    "                            c0 = self.m0_chromatid,\n",
    "                            c1 = self.m1_chromatid,\n",
    "                            chiasma = chiasma,\n",
    "                            flag = chiasma_flag\n",
    "                        )\n",
    "                    else:\n",
    "                        chiasma_flag = self.homologous_recombination(\n",
    "                            transcript_entry = transcript_entry,\n",
    "                            updated_c0 = updated_p0,\n",
    "                            updated_c1 = updated_p1,\n",
    "                            c0 = self.p0_chromatid,\n",
    "                            c1 = self.p1_chromatid,\n",
    "                            chiasma = chiasma,\n",
    "                            flag = chiasma_flag\n",
    "                        )\n",
    "\n",
    "        m_chromatid = self.chromosome_inheritance(updated_m0, updated_m1)\n",
    "        p_chromatid = self.chromosome_inheritance(updated_p0, updated_p1)\n",
    "        \n",
    "        return m_chromatid,p_chromatid\n",
    "    \n",
    "    def homologous_recombination(self,transcript_entry,updated_c0,updated_c1,c0,c1,chiasma,flag):\n",
    "        \"\"\"\n",
    "        for a given transcript entry, simulate process of homologous recombination, given\n",
    "        a uniformly selected chiasma point. \n",
    "        \"\"\"\n",
    "        \n",
    "        gene,chrom,start,end,direction,sequence = transcript_entry\n",
    "        \n",
    "        # 1 means chiasma has not been reached; 0 means passed chiasma\n",
    "        if flag <= start and flag == 1:\n",
    "            flag = 0\n",
    "            \n",
    "            # Case where chiasma point lies within a gene\n",
    "            if chiasma in range(start,start+len(sequence)):\n",
    "                updated_c0[chrom][gene] = c0[chrom][gene][:chiasma]+c1[chrom][gene][chiasma:]\n",
    "                updated_c1[chrom][gene] = c1[chrom][gene][:chiasma]+c0[chrom][gene][chiasma:]\n",
    "                return flag\n",
    "\n",
    "        if flag == 1: # Before chiasma point has been reached\n",
    "            updated_c0[chrom][gene] = c0[chrom][gene]\n",
    "            updated_c1[chrom][gene] = c1[chrom][gene]\n",
    "        else: # After chiasma point has been reached\n",
    "            updated_c0[chrom][gene] = c1[chrom][gene]\n",
    "            updated_c1[chrom][gene] = c0[chrom][gene]\n",
    "        \n",
    "        return flag\n",
    "    \n",
    "    def chromosome_inheritance(self,c0,c1):\n",
    "        \"\"\"\n",
    "        Given homologous chromosomes, randomly select one to be inherited by embryo\n",
    "        \"\"\"\n",
    "        \n",
    "        chromatid = defaultdict(dict)\n",
    "        for chrom in c0:\n",
    "            chromatid[chrom] = c0[chrom] if random.random() <= 0.5 else c1[chrom]\n",
    "        \n",
    "        return chromatid\n",
    "                  \n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "genetic-passenger",
   "metadata": {},
   "source": [
    "## Initialize Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "mediterranean-ireland",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-09-08T23:37:16.296863Z",
     "start_time": "2022-09-08T23:37:16.293388Z"
    }
   },
   "outputs": [],
   "source": [
    "N_EMBRYOS = 100\n",
    "NUM_PROC = 50"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "according-circular",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-09-08T23:37:38.538234Z",
     "start_time": "2022-09-08T23:37:17.932944Z"
    }
   },
   "outputs": [],
   "source": [
    "df = pd.read_csv(INPUT_PATH)\n",
    "df = df.dropna()\n",
    "\n",
    "# Read the full counts without downsampling\n",
    "count_df_full = pd.read_csv(COUNTS_PATH)\n",
    "count_df_full = count_df_full[count_df_full[\"Lv_name\"] != \"LVA_m28240.t1\"]\n",
    "\n",
    "# Convert to anndata so we can downsample with scanpy\n",
    "adata_counts_full = anndata.AnnData(X=count_df_full.iloc[:, 2:].to_numpy().T,\n",
    "                               obs=pd.DataFrame(index=count_df_full.iloc[:, 2:].columns),\n",
    "                               var=pd.DataFrame(index=count_df_full['Lv_name']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "distributed-briefing",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-09-08T23:38:22.872072Z",
     "start_time": "2022-09-08T23:37:38.540548Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/mnt/geofflab/jupyterhub/anaconda3/lib/python3.7/site-packages/ipykernel/ipkernel.py:287: DeprecationWarning: `should_run_async` will not call `transform_cell` automatically in the future. Please pass the result to `transformed_cell` argument and any exception that happen during thetransform in `preprocessing_exc_tuple` in IPython 7.17 and above.\n",
      "  and should_run_async(code)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "aeb2ef7a0e184577808ce8f170940619",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/29836 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Dowsample all sequences to max 150 bp\n",
    "for ind in tqdm(df.index):\n",
    "    start = df.loc[ind, 'start']\n",
    "    end = df.loc[ind, 'end']\n",
    "    sequence = df.loc[ind, 'sequence']\n",
    "    \n",
    "    # If a sequence is longer than 150, trim it\n",
    "    if np.absolute(end-start) > 150:\n",
    "        df.loc[ind, 'end'] = start + 150\n",
    "        df.loc[ind, 'sequence'] = sequence[:150]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "progressive-numbers",
   "metadata": {},
   "source": [
    "## Simulate Test Data\n",
    "\n",
    "We need to simulate variant call matrices for a mix of downsampling levels."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "excess-indonesian",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-09-08T23:38:22.999113Z",
     "start_time": "2022-09-08T23:38:22.875586Z"
    }
   },
   "outputs": [],
   "source": [
    "# Get the avg and total UMI for the base counts matrix\n",
    "avg_umi_full = np.average(np.sum(adata_counts_full.X, axis=1))\n",
    "total_counts_full = np.sum(adata_counts_full.X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "announced-information",
   "metadata": {
    "ExecuteTime": {
     "start_time": "2022-09-08T23:37:21.227Z"
    },
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "92dd91ccba984e718dd0323458b8ea14",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Embryo 0:   0%|          | 0/18 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b7383f3b93a24f66975fe43bbc37a0f0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Embryo 1:   0%|          | 0/21 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f22e055b7109424fb0d5bb80102d74c2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Embryo 2:   0%|          | 0/19 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "cdcb7d85121c4030821a5bbcfdd30d86",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Embryo 3:   0%|          | 0/19 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0c6be49a27f247138970cc239a06c96d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Embryo 4:   0%|          | 0/18 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ada7a75ad6c84cfaaa64b8c366a8a6ca",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Embryo 5:   0%|          | 0/20 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "49dfd8dd7799446db09ef4f75f8712d5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Embryo 6:   0%|          | 0/22 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b786a1a6fc5f4cc9a201488638e38e9a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Embryo 7:   0%|          | 0/20 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "65571d790671476e951b11de0516c0dd",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Embryo 8:   0%|          | 0/24 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6905c62cae81457a8dbd84ce382d8fa4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Embryo 9:   0%|          | 0/17 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "aba910834d384a4381e0fd053c18ac23",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Embryo 10:   0%|          | 0/18 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "12833b134a1e495ab2ff946483fc7236",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Embryo 11:   0%|          | 0/20 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4ff7d0bfb81a4afe952df1d95f11198a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Embryo 12:   0%|          | 0/19 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6911af2743b248ed89483303f76afad6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Embryo 13:   0%|          | 0/22 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "11e375437e564020856f6513b92024d4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Embryo 14:   0%|          | 0/16 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "414b7d42e35e485bae6cf6aa58f71471",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Embryo 15:   0%|          | 0/20 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c3b35be29813402eb448017dcd85e015",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Embryo 16:   0%|          | 0/21 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e7e5d4de450746088c3653bc1532063d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Embryo 17:   0%|          | 0/24 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "da0d5c15241b47a6a47f8f779d3865e1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Embryo 18:   0%|          | 0/24 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f7db809ec11540d1b85c4c27d50fab68",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Embryo 19:   0%|          | 0/24 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "974d521db5484a87a5e3a96173d18d1f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Embryo 20:   0%|          | 0/22 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b2651a422630422785fe120e836d6e27",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Embryo 21:   0%|          | 0/16 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6a98dd645c4846d0a5197ed7fff834c9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Embryo 22:   0%|          | 0/21 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "bf75c8abf8e3463f9223c07568837957",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Embryo 23:   0%|          | 0/19 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9681d88d47c1420aae29db11184b7fcb",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Embryo 24:   0%|          | 0/17 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f5d44509b8a34fa9a8f2d33e53d57545",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Embryo 25:   0%|          | 0/14 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3dcd3ce3a7f341a7907e6b12c07bd043",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Embryo 26:   0%|          | 0/21 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2edd7f428f0e4471b9eb9fe6df13c437",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Embryo 27:   0%|          | 0/15 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "dfe26cb2e1714a649985bf6e0aa8d244",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Embryo 28:   0%|          | 0/20 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "dcaaa7f827db49edbee680fa027fad7e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Embryo 29:   0%|          | 0/24 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "fe6cf98ee6074a32a31472f25cd7aa94",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Embryo 30:   0%|          | 0/17 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# The fraction of counts we should retain for each run\n",
    "DS_LEVELS = [250, 750, 1250, 1750, np.floor(avg_umi_full)]\n",
    "\n",
    "variant_mats = []\n",
    "true_clusterings = []\n",
    "avg_umi = []\n",
    "\n",
    "# Downsample the counts matrix to each level and generate data\n",
    "for ds_level in DS_LEVELS:  \n",
    "    counts_target = adata_counts_full.shape[0]*ds_level\n",
    "    \n",
    "    # Downsample the matrix\n",
    "    adata_counts = adata_counts_full.copy()\n",
    "    scanpy.pp.downsample_counts(adata_counts, total_counts=counts_target)\n",
    "    avg_umi.append(np.average(np.sum(adata_counts.X, axis=1)))\n",
    "        \n",
    "    # Generate the embryos\n",
    "    simulator = EmbryoSequenceSimulator(df, N_EMBRYOS)\n",
    "    X,true_clusters = simulator.embryo_population_simulation()\n",
    "    \n",
    "    variant_mats.append(X)\n",
    "    true_clusterings.append(true_clusters)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "elder-definition",
   "metadata": {
    "ExecuteTime": {
     "start_time": "2022-09-08T23:37:22.173Z"
    }
   },
   "outputs": [],
   "source": [
    "def adjustedHamming(g0, g1):\n",
    "# Computes a hamming distance normalized by where we have\n",
    "# data. ie. entries are not -1.\n",
    "    if len(g0) != len(g1):\n",
    "        raise ValueError(\"Sequence lengths unequal.\")\n",
    "    else:\n",
    "        hd,adjlen = 0, 0\n",
    "        for i, j in zip(g0, g1):\n",
    "            if i == -1 or j == -1: \n",
    "                continue\n",
    "            \n",
    "            adjlen += 1\n",
    "            \n",
    "            if i != j: \n",
    "                hd += 1\n",
    "                \n",
    "        if adjlen == 0:\n",
    "            return np.inf\n",
    "        else:\n",
    "            return hd/adjlen\n",
    "\n",
    "def compute_row_ham_dists(i):\n",
    "# Compute a row of hamming dists\n",
    "    row_hd = np.zeros(N-i)\n",
    "    \n",
    "    for j in range(i, N):\n",
    "        hd = adjustedHamming(X[i,:], X[j,:])\n",
    "        row_hd[j-i] = hd\n",
    "        \n",
    "    return row_hd\n",
    "\n",
    "ham_dists_ds = []\n",
    "\n",
    "# Compute the hamming dist matrices for each of the downsamples\n",
    "for i in range(len(variant_mats)):\n",
    "    X = variant_mats[i]\n",
    "    N = X.shape[0]\n",
    "\n",
    "    with Pool(NUM_PROC) as p:\n",
    "        ham_dists = list(tqdm(p.imap(compute_row_ham_dists, range(N)), total=N))\n",
    "\n",
    "    hd = np.zeros((N, N))\n",
    "\n",
    "    for i in range(N):\n",
    "        hd[i, i:] = ham_dists[i]\n",
    "\n",
    "    hd = hd + hd.T\n",
    "    \n",
    "    ham_dists_ds.append(hd)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "criminal-webmaster",
   "metadata": {
    "ExecuteTime": {
     "start_time": "2022-09-08T23:37:23.339Z"
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "clustering_perfs = []\n",
    "\n",
    "for i, hd in enumerate(ham_dists_ds):\n",
    "    fig,ax = plt.subplots(figsize=(9,7))\n",
    "    h1 = ax.imshow(hd, aspect='auto')\n",
    "    fig.colorbar(h1, ax=ax)\n",
    "    plt.show()\n",
    "    \n",
    "    # Cluster the distance matrix\n",
    "    clusters = SpectralClustering(n_clusters=N_EMBRYOS,\n",
    "                                  assign_labels=\"kmeans\", affinity='precomputed').fit(np.exp(-hd**2))\n",
    "    rand_score = adjusted_rand_score(true_clusterings[i],clusters.labels_)\n",
    "    \n",
    "    clustering_perfs.append(rand_score)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cathedral-yahoo",
   "metadata": {},
   "source": [
    "## Create Clustering Performance Figure"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "chief-oasis",
   "metadata": {
    "ExecuteTime": {
     "start_time": "2022-09-08T23:37:25.129Z"
    }
   },
   "outputs": [],
   "source": [
    "clustering_perfs, avg_umi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "radio-pharmacy",
   "metadata": {
    "ExecuteTime": {
     "start_time": "2022-09-08T23:37:25.881Z"
    },
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# Plot performance vs. UMI per cell\n",
    "plt.figure(figsize=(10, 10), dpi=600)\n",
    "\n",
    "plt.plot(avg_umi, clustering_perfs, '-o', lw=5, markersize=14)\n",
    "\n",
    "plt.yticks([0, 0.2, 0.4, 0.6, 0.8, 1.0], fontsize=24)\n",
    "plt.xticks(range(250, 2500, 500), fontsize=24, rotation=45)\n",
    "\n",
    "plt.ylabel('Clustering Performance (ARI)', fontsize=28, labelpad=10)\n",
    "plt.xlabel('Average UMI Counts per Cell', fontsize=28, labelpad=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "natural-madison",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "hide_input": false,
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
